<html><head><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><title>Aloha</title><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="Generic machine learning, lazy features" /><meta name="author" content="eHarmony" /><meta name="og:image" content="/aloha/img/poster.png" /><meta name="og:title" content="Aloha" /><meta name="og:site_name" content="Aloha" /><meta name="og:url" content="http://eharmony.github.io/aloha" /><meta name="og:type" content="website" /><meta name="og:description" content="Generic machine learning, lazy features" /><meta name="twitter:image" content="/aloha/img/poster.png" /><meta name="twitter:card" content="summary_large_image" /><meta name="twitter:site" content="" /><meta name="kazari-dependencies" content="" /><meta name="kazari-resolvers" content="" /><link rel="icon" type="image/png" href="/aloha/img/favicon.png" /><link rel="icon" type="image/png" sizes="16x16" href="/aloha/img/favicon16x16.png" /><link rel="icon" type="image/png" sizes="24x24" href="/aloha/img/favicon24x24.png" /><link rel="icon" type="image/png" sizes="32x32" href="/aloha/img/favicon32x32.png" /><link rel="icon" type="image/png" sizes="48x48" href="/aloha/img/favicon48x48.png" /><link rel="icon" type="image/png" sizes="57x57" href="/aloha/img/favicon57x57.png" /><link rel="icon" type="image/png" sizes="60x60" href="/aloha/img/favicon60x60.png" /><link rel="icon" type="image/png" sizes="64x64" href="/aloha/img/favicon64x64.png" /><link rel="icon" type="image/png" sizes="70x70" href="/aloha/img/favicon70x70.png" /><link rel="icon" type="image/png" sizes="72x72" href="/aloha/img/favicon72x72.png" /><link rel="icon" type="image/png" sizes="76x76" href="/aloha/img/favicon76x76.png" /><link rel="icon" type="image/png" sizes="96x96" href="/aloha/img/favicon96x96.png" /><link rel="icon" type="image/png" sizes="114x114" href="/aloha/img/favicon114x114.png" /><link rel="icon" type="image/png" sizes="120x120" href="/aloha/img/favicon120x120.png" /><link rel="icon" type="image/png" sizes="128x128" href="/aloha/img/favicon128x128.png" /><link rel="icon" type="image/png" sizes="144x144" href="/aloha/img/favicon144x144.png" /><link rel="icon" type="image/png" sizes="150x150" href="/aloha/img/favicon150x150.png" /><link rel="icon" type="image/png" sizes="152x152" href="/aloha/img/favicon152x152.png" /><link rel="icon" type="image/png" sizes="196x196" href="/aloha/img/favicon196x196.png" /><link rel="icon" type="image/png" sizes="310x310" href="/aloha/img/favicon310x310.png" /><link rel="icon" type="image/png" sizes="310x150" href="/aloha/img/favicon310x150.png" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/aloha/highlight/styles/atom-one-light.css" /><link rel="stylesheet" href="/aloha/css/style.css" /><link rel="stylesheet" href="/aloha/css/palette.css" /><link rel="stylesheet" href="/aloha/css/codemirror.css" /><link rel="stylesheet" href="/aloha/css/kazari-style.css" /><link rel="stylesheet" href="/aloha/css/solarized-dark.css" /><link rel="stylesheet" href="/aloha/css/override.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><ul id="sidebar" class="sidebar-nav"><li class="sidebar-brand"><a href="/aloha/" class="brand"><div class="brand-wrapper"><span>Aloha</span></div></a></li> <li><a href="/aloha/docs/api/index.html" class="">API Docs</a></li> <li><a href="/aloha/docs/getting_started.html" class="">Getting Started (Data Sci)</a></li> <li><a href="/aloha/docs/getting_started_eng.html" class="">Getting Started (Data Eng)</a></li> <li><a href="/aloha/docs/dataset.html" class="">Constructing Datasets</a></li> <li><a href="/aloha/docs/in_depth_walkthrough.html" class="">In Depth Walkthrough</a></li> <li><a href="/aloha/docs/model_formats.html" class="">Model Formats</a></li> <li><a href="/aloha/docs/release_notes.html" class="">Release Notes</a></li></ul></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li id="gh-eyes-item" class="hidden-xs"><a href="https://github.com/eharmony/aloha"><i class="fa fa-eye"></i><span>WATCH<span id="eyes" class="label label-default">--</span></span></a></li><li id="gh-stars-item" class="hidden-xs"><a href="https://github.com/eharmony/aloha"><i class="fa fa-star-o"></i><span>STARS<span id="stars" class="label label-default">--</span></span></a></li><li><a href="#" onclick="shareSiteTwitter('Aloha Generic machine learning, lazy features');"><i class="fa fa-twitter"></i></a></li><li><a href="#" onclick="shareSiteFacebook('Aloha Generic machine learning, lazy features');"><i class="fa fa-facebook"></i></a></li><li><a href="#" onclick="shareSiteGoogle();"><i class="fa fa-google-plus"></i></a></li></ul></div></div></div></div><div id="content" data-github-owner="eharmony" data-github-repo="aloha"><div class="content-wrapper"><section><h1 id="getting-started-data-scientists">Getting Started (Data Scientists)</h1>

<p>This section will walk through downloading and building Aloha as well as doing some simple tasks in the command
line interface (CLI) like generating datasets, creating models and using models to make predictions.</p>

<h2 id="build-prerequisites">Build Prerequisites</h2>

<p>Aloha uses <a href="http://www.scala-sbt.org">SBT</a> for building.</p>

<h3 id="installing-sbt-on-a-mac">Installing SBT on a <em>Mac</em></h3>

<p>The preferred way to install SBT on a <em>Mac</em> is by using the <a href="http://http://brew.sh">Homebrew</a> package manager.  If
you have Homebrew installed, just install via:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>brew install sbt
</code></pre>
</div>

<h3 id="installing-homebrew-on-a-mac">Installing Homebrew on a <em>Mac</em></h3>

<p>If you don’t have Homebrew installed, follow the instructions at <a href="http://brew.sh">http://brew.sh</a>.</p>

<h3 id="installing-sbt-manually">Installing SBT Manually</h3>

<p><a href="http://www.scala-sbt.org/download.html">Download it here</a>.</p>

<h2 id="get-aloha-from-source">Get Aloha from Source</h2>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>git clone git@github.com:eHarmony/aloha.git
<span class="nb">cd </span>aloha
</code></pre>
</div>

<h3 id="installing-to-ivy-local-cache">Installing to Ivy Local Cache</h3>

<p>This can be accomplished via one of the following.  Choose the most appropriate for you.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>sbt ++2.11.8 clean publishLocal  <span class="c"># For Scala 2.11 version</span>
sbt ++2.10.5 clean publishLocal  <span class="c"># For Scala 2.10 version</span>
sbt +clean +publishLocal         <span class="c"># For all Scala versions</span>
</code></pre>
</div>

<h3 id="installing-to-maven-local-repository">Installing to Maven Local Repository</h3>

<p>Similarly, you can publish to you local Maven repository via one of the following.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>sbt ++2.11.8 clean publishM2  <span class="c"># For Scala 2.11 version</span>
sbt ++2.10.5 clean publishM2  <span class="c"># For Scala 2.10 version</span>
sbt +clean +publishM2         <span class="c"># For all Scala versions</span>
</code></pre>
</div>

<h2 id="generating-a-local-copy-of-the-documentation">Generating a Local Copy of the Documentation</h2>

<h3 id="prerequisites">Prerequisites</h3>

<p>Aloha uses <a href="https://47deg.github.io/sbt-microsites/">sbt-microsites</a> to generate site documentation.  To create
locally, you’ll need <a href="https://jekyllrb.com/">Jekyll</a>.  There are a bunch of ways to get Jekyll, but the easiest
is with one of the following:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>gem install jekyll        <span class="c"># Via ruby gems installer</span>
yum install jekyll        <span class="c"># via Yum, typically on RedHat and variants</span>
apt-get install jekyll    <span class="c"># via apt-get, typically on Debian and variants</span>
</code></pre>
</div>

<h3 id="site-generation">Site Generation</h3>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>sbt makeMicrosite <span class="o">&amp;&amp;</span> jekyll serve -s docs/target/site -d docs/target/site/_site
</code></pre>
</div>

<p>Then you should be able to open a browser to <a href="http://localhost:4000/aloha/">http://localhost:4000/aloha/</a> to see the
documentation.  To stop the webserver provided by Jekyll, Just press <code class="highlighter-rouge">ctrl-c</code>.</p>

<h2 id="create-a-vw-dataset">Create a VW Dataset</h2>

<blockquote>
  <p><strong>NOTE</strong>: <em>CLI</em> examples require running <code class="highlighter-rouge">sbt test:compile</code> prior to execution.  This is necessary because Aloha
no longer publishes a <em>CLI</em> uberjar.  Therefore, we want the Aloha classfiles to be on the classpath.</p>
</blockquote>

<p><em><a href="http://www.eharmony.com">eHarmony</a></em> uses <a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">Vowpal Wabbit</a> for many
of its predictive tasks so Aloha provides support for VW including dataset creation and native VW model creation on the 
<a href="https://en.wikipedia.org/wiki/Java_virtual_machine">JVM</a>.</p>

<p><span class="label">bash script</span></p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="c"># The classpath argument contains the protocol buffer definitions.</span>
<span class="c">#</span>
aloha-cli/bin/aloha-cli                                  <span class="se">\</span>
  -cp <span class="s1">'aloha-io-proto/target/scala-2.11/test-classes'</span>    <span class="se">\</span>
  --dataset                                              <span class="se">\</span>
  -s <span class="k">$(</span>find <span class="nv">$PWD</span>/aloha-cli/src -name <span class="s1">'proto_spec2.json'</span><span class="k">)</span> <span class="se">\</span>
  -p <span class="s1">'com.eharmony.aloha.test.proto.Testing.UserProto'</span>   <span class="se">\</span>
  -i <span class="k">$(</span>find <span class="nv">$PWD</span>/aloha-core/src -name <span class="s1">'fizz_buzzs.proto'</span><span class="k">)</span><span class="se">\</span>
  --vw_labeled /tmp/dataset.vw
</code></pre>
</div>

<p><span class="label label-success">/tmp/dataset.vw</span></p>

<pre>
1 1| name=Alan gender=MALE bmi:23 |photos num_photos:2 avg_photo_height
1 1| name=Kate gender=FEMALE bmi=UNK |photos num_photos avg_photo_height:3
</pre>

<p>Let’s break down the preceding example.  <code class="highlighter-rouge">-cp</code> was specified to provide additional classpath elements.  This argument
is currently required can be <code class="highlighter-rouge">''</code> if no additional classpath elements are required.  In this example, we included the
directory that contains the necessary protocol buffer classfiles for <code class="highlighter-rouge">com.eharmony.aloha.test.proto.Testing.UserProto</code>.</p>

<p>After the <code class="highlighter-rouge">-cp</code> flag always comes the subtask.  Here the subtask is creating a dataset, denoted by the <code class="highlighter-rouge">--dataset</code>
flag.  To see additional subtasks available, you can omit the subtask flag and the subsequent parameters and the
Aloha CLI will provide sensible context-sensitive error messages.</p>

<p><code class="highlighter-rouge">-s</code> tells where to get the Aloha feature specification file that will be used to extract data from the protocol
buffer instances provided as the raw data.  This file can be local or remote and is an
<a href="https://commons.apache.org/proper/commons-vfs/">Apache VFS</a> URL.</p>

<p><code class="highlighter-rouge">-p</code> along with the <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Class.html#getCanonicalName\(\)">canonical class name</a>
tells that the input type of the raw data is line-separated base64-encoded protocol buffer input.</p>

<p><code class="highlighter-rouge">-i</code> tells where the raw input data resides.  If the <code class="highlighter-rouge">-i</code> argument is omitted, the CLI reads from standard
input.  This is nice when you want to pipe input to the Aloha CLI from another process.  Again, if supplied, Aloha
expects the argument to be and Apache VFS URL.</p>

<p>Finally, <code class="highlighter-rouge">--vw_labeled</code> tells Aloha to generated a labeled VW dataset and output it to <code class="highlighter-rouge">tmp/dataset.vw</code>.  Like with
other <em>*nix</em> commands,  you can provide <code class="highlighter-rouge">-</code> as a value and the CLI will output to standard out.</p>

<h3 id="create-a-vw-dataset-programmatically">Create a VW dataset programmatically</h3>

<div class="language-scala highlighter-rouge"><pre class="highlight"><code><span class="k">import</span> <span class="nn">java.io.File</span>
<span class="k">import</span> <span class="nn">scala.util.Try</span>
<span class="k">import</span> <span class="nn">scala.concurrent.ExecutionContext.Implicits.global</span>
<span class="k">import</span> <span class="nn">com.google.protobuf.GeneratedMessage</span>
<span class="k">import</span> <span class="nn">com.eharmony.aloha.reflect.RefInfo</span>
<span class="k">import</span> <span class="nn">com.eharmony.aloha.dataset.</span><span class="o">{</span><span class="nc">RowCreator</span><span class="o">,</span> <span class="nc">RowCreatorProducer</span><span class="o">,</span> <span class="nc">RowCreatorBuilder</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.eharmony.aloha.dataset.vw.labeled.VwLabelRowCreator</span>
<span class="k">import</span> <span class="nn">com.eharmony.aloha.semantics.compiled.CompiledSemantics</span>
<span class="k">import</span> <span class="nn">com.eharmony.aloha.semantics.compiled.compiler.TwitterEvalCompiler</span>
<span class="k">import</span> <span class="nn">com.eharmony.aloha.semantics.compiled.plugin.proto.CompiledSemanticsProtoPlugin</span>
<span class="k">import</span> <span class="nn">com.eharmony.aloha.test.proto.Testing.UserProto</span>
<span class="k">import</span> <span class="nn">com.eharmony.aloha.dataset.MissingAndErroneousFeatureInfo</span>

<span class="k">def</span> <span class="n">getRowCreator</span><span class="o">[</span><span class="kt">T</span> <span class="k">&lt;:</span> <span class="kt">GeneratedMessage</span> <span class="kt">:</span> <span class="kt">RefInfo</span>, <span class="kt">S</span> <span class="k">&lt;:</span> <span class="kt">RowCreator</span><span class="o">[</span><span class="kt">T</span><span class="o">]](</span>
    <span class="n">producers</span><span class="k">:</span> <span class="kt">List</span><span class="o">[</span><span class="kt">RowCreatorProducer</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">S</span><span class="o">]],</span> 
    <span class="n">alohaJsonSpecFile</span><span class="k">:</span> <span class="kt">File</span><span class="o">,</span>
    <span class="n">alohaCacheDir</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">File</span><span class="o">]</span> <span class="k">=</span> <span class="nc">None</span><span class="o">)</span><span class="k">:</span> <span class="kt">Try</span><span class="o">[</span><span class="kt">S</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">plugin</span> <span class="k">=</span> <span class="nc">CompiledSemanticsProtoPlugin</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
  <span class="k">val</span> <span class="n">compiler</span> <span class="k">=</span> <span class="nc">TwitterEvalCompiler</span><span class="o">(</span><span class="n">classCacheDir</span> <span class="k">=</span> <span class="n">alohaCacheDir</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">imports</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Nil</span> <span class="c1">// Imports for UDFs to use in extraction functions.
</span>  <span class="k">val</span> <span class="n">semantics</span> <span class="k">=</span> <span class="nc">CompiledSemantics</span><span class="o">(</span><span class="n">compiler</span><span class="o">,</span> <span class="n">plugin</span><span class="o">,</span> <span class="n">imports</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">specBuilder</span> <span class="k">=</span> <span class="nc">RowCreatorBuilder</span><span class="o">(</span><span class="n">semantics</span><span class="o">,</span> <span class="n">producers</span><span class="o">)</span>

  <span class="c1">// There are many other factory methods for various input types: VFS, Strings, etc.
</span>  <span class="n">specBuilder</span><span class="o">.</span><span class="n">fromFile</span><span class="o">(</span><span class="n">alohaJsonSpecFile</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">alohaRoot</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">File</span><span class="o">(</span><span class="k">new</span> <span class="nc">File</span><span class="o">(</span><span class="s">"."</span><span class="o">).</span><span class="n">getAbsolutePath</span><span class="o">.</span><span class="n">replaceFirst</span><span class="o">(</span><span class="s">"/aloha/.*$"</span><span class="o">,</span> <span class="s">"/aloha/"</span><span class="o">))</span>
<span class="k">val</span> <span class="n">myAlohaJsonSpecFile</span> <span class="k">=</span>
  <span class="k">new</span> <span class="nc">File</span><span class="o">(</span><span class="n">alohaRoot</span><span class="o">,</span> <span class="s">"aloha-cli/src/test/resources/com/eharmony/aloha/cli/dataset/proto_spec2.json"</span><span class="o">)</span>

<span class="c1">// No cache dir in this example.
</span><span class="k">val</span> <span class="n">alohaCacheDir</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">File</span><span class="o">]</span> <span class="k">=</span> <span class="nc">None</span>

<span class="c1">// Try[VwLabelRowCreator[UserProto]]
</span><span class="k">val</span> <span class="n">creatorTry</span> <span class="k">=</span> <span class="n">getRowCreator</span><span class="o">(</span><span class="nc">List</span><span class="o">(</span><span class="k">new</span> <span class="nc">VwLabelRowCreator</span><span class="o">.</span><span class="nc">Producer</span><span class="o">[</span><span class="kt">UserProto</span><span class="o">]),</span>
                               <span class="n">myAlohaJsonSpecFile</span><span class="o">,</span>
                               <span class="n">alohaCacheDir</span><span class="o">)</span>

<span class="c1">// Throws if the creator wasn't produced.  This might be desirable for
// short-circuiting in initialization code.
</span><span class="k">val</span> <span class="n">creator</span> <span class="k">=</span> <span class="n">creatorTry</span><span class="o">.</span><span class="n">get</span>

<span class="c1">// Create a dataset row with an instance of UserProto.
// In real usage, get a real sequence.
</span><span class="k">val</span> <span class="n">users</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">UserProto</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Nil</span>

<span class="k">val</span> <span class="n">results</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[(</span><span class="kt">MissingAndErroneousFeatureInfo</span>, <span class="kt">CharSequence</span><span class="o">)]</span> <span class="k">=</span>
  <span class="n">users</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">u</span> <span class="k">=&gt;</span> <span class="n">creator</span><span class="o">(</span><span class="n">u</span><span class="o">))</span>
</code></pre>
</div>

<h3 id="dataset-types">Dataset types</h3>

<p>Aloha currently supports creating the following types of datasets:</p>

<p>vw, vw_labeled, vw_cb, libsvm, libsvm_labeled, csv</p>
<ol>
  <li>Unlabeled <a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format">VW</a> datasets using the <code class="highlighter-rouge">--vw</code> flag</li>
  <li>Labeled <a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format">VW</a> datasets using the <code class="highlighter-rouge">--vw_labeled</code> flag</li>
  <li>Contextual Bandit <a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format">VW</a> datasets using the <code class="highlighter-rouge">--vw_cb</code> flag</li>
  <li>Unlabeled <a href="http://www.quora.com/What-is-this-data-format-in-LIBSVM-training-dataset">LIBSVM</a> using the <code class="highlighter-rouge">--libsvm</code> flag</li>
  <li>Labeled <a href="http://www.quora.com/What-is-this-data-format-in-LIBSVM-training-dataset">LIBSVM</a> using the <code class="highlighter-rouge">--libsvm_labeled</code> flag</li>
  <li><a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a> datasets using the <code class="highlighter-rouge">--csv</code> flag</li>
</ol>

<p>One can generate compatible dataset types simultaneously for the same dataset by including the dataset <em>type</em> flag 
along with the file to which the dataset should be output.  To output to standard out, use the filename <code class="highlighter-rouge">-</code>.  Note
that only one dataset can be output to a given file.  Outputting two or more datasets to the same output file has 
undefined behaviour.</p>

<h2 id="create-a-vw-model">Create a VW Model</h2>

<p>Given our dataset in <code class="highlighter-rouge">/tmp/dataset.vw</code>, we can create a VW model with the normal procedure.  For instance, to create 
a simple logistic regression model with all default parameters and one pass over the data, do:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>vw -d /tmp/dataset.vw --link logistic --loss_function logistic --readable_model /tmp/model_readable.vw -f /tmp/model.vw
</code></pre>
</div>

<p>This creates the binary model <code class="highlighter-rouge">/tmp/model.vw</code> and a human-readable model <code class="highlighter-rouge">/tmp/model_readable.vw</code>.</p>

<h3 id="verifying-the-model">Verifying the Model</h3>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>vw -d /tmp/dataset.vw --loss_function logistic -i /tmp/model.vw -t 
</code></pre>
</div>

<p><span class="label label-success">output</span></p>

<pre>
only testing
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = /tmp/dataset.vw
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.310707 0.310707            1            1.0   1.0000   0.7329        6
0.296281 0.281855            2            2.0   1.0000   0.7544        6

finished run
number of examples per pass = 2
passes used = 1
weighted example sum = 2.000000
weighted label sum = 2.000000
average loss = 0.296281
best constant = 1.000000
best constant's loss = 0.313262
total feature number = 12
</pre>

<h2 id="creating-an-aloha-model">Creating an Aloha Model</h2>

<p>To create an Aloha model, we need two things.  The first is the specification file used to create the dataset.  The 
second is the binary VW model.  To build the model, we just use the CLI again.</p>

<p><span class="label">bash script</span></p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>aloha-cli/bin/aloha-cli                                       <span class="se">\</span>
  -cp <span class="s1">''</span>                                                      <span class="se">\</span>
  --vw                                                        <span class="se">\</span>
  --vw-args <span class="s2">"--quiet -t"</span>                                      <span class="se">\</span>
  --spec <span class="k">$(</span>find <span class="nv">$PWD</span>/aloha-cli/src -name <span class="s1">'proto_spec2.json'</span><span class="k">)</span>  <span class="se">\</span>
  --model /tmp/model.vw                                       <span class="se">\</span>
  --name <span class="s2">"test-model"</span>                                         <span class="se">\</span>
  --id 101                                                    <span class="se">\</span>
| tee /tmp/aloha-vw-model.json
</code></pre>
</div>

<p>This prints to <em>STDOUT</em> JSON similar to the following.  The following has rearranged key-value pairs and added 
whitespace.  Under the <a href="http://json.org">JSON specification</a>, this is equivalent to the JSON printed by the 
above command.</p>

<p><span class="label label-success">/tmp/aloha-vw-model.json</span></p>

<div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nt">"modelType"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VwJNI"</span><span class="p">,</span><span class="w">
  </span><span class="nt">"modelId"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">"id"</span><span class="p">:</span><span class="w"> </span><span class="mi">101</span><span class="p">,</span><span class="w"> </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"test-model"</span><span class="w"> </span><span class="p">},</span><span class="w">
  </span><span class="nt">"features"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"name"</span><span class="p">:</span><span class="w">   </span><span class="p">{</span><span class="w"> </span><span class="nt">"spec"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ind(${name})"</span><span class="p">,</span><span class="w">   </span><span class="nt">"defVal"</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="s2">"=UNK"</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">]]</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="nt">"gender"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">"spec"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ind(${gender})"</span><span class="p">,</span><span class="w"> </span><span class="nt">"defVal"</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="s2">"=UNK"</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">]]</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="nt">"bmi"</span><span class="p">:</span><span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nt">"spec"</span><span class="p">:</span><span class="w"> </span><span class="s2">"${bmi}"</span><span class="p">,</span><span class="w">         </span><span class="nt">"defVal"</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="s2">"=UNK"</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">]]</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="nt">"num_photos"</span><span class="p">:</span><span class="w"> </span><span class="s2">"${photos}.size"</span><span class="p">,</span><span class="w">
    </span><span class="nt">"avg_photo_height"</span><span class="p">:</span><span class="w"> </span><span class="s2">"{ val hs = ${photos.height};  hs.flatten.sum / hs.filter(_.nonEmpty).size }"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nt">"namespaces"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"photos"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="s2">"num_photos"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"avg_photo_height"</span><span class="w">
    </span><span class="p">]</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nt">"vw"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"model"</span><span class="p">:</span><span class="w"> </span><span class="s2">"[ base64-encoded data omitted ]"</span><span class="p">,</span><span class="w">
    </span><span class="nt">"params"</span><span class="p">:</span><span class="w"> </span><span class="s2">"--quiet -t"</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>

<h3 id="inline-models-cannot-exceed-2gb">Inline Models Cannot Exceed 2GB</h3>

<p>Since the JVM arrays are indexed by 32-bit integers, and JVM Strings are backed by arrays, the largest
String available able on the JVM is 2^(32 - 1) - 1 or about 2 billion characters.  Consequently, large base-64 encoded
binary models that are embedded into the JSON will cause failures.  These may be easy or hard to find.  For instance,
one of the more subtle errors may be attempting to create an array of negative size.  This would most likely arise from
a large model whose size in bytes is a number larger than a 32-bit integer can represent.</p>

<p>To overcome this, specify the <code class="highlighter-rouge">--external</code> flag when creating a model and provide an Apache VFS URL to the model.
When the Aloha model is parsed, the underlying machine learned model resource will be retrieved using this URL.</p>

<h2 id="aloha-model-prediction-via-cli">Aloha Model Prediction via CLI</h2>

<p>To perform predictions using the command line interface, one needs to use the <code class="highlighter-rouge">--modelrunner</code> flag.  There are
many options for this.  The most import here are:</p>

<ul>
  <li><code class="highlighter-rouge">-A</code> which adds the input after the predictions.  Since no separator was provided, <em>TAB</em> is used to separate 
the predictions and the input data.  It’s easy to change the separator using the <code class="highlighter-rouge">--outsep</code> flag.</li>
  <li><code class="highlighter-rouge">--output-type</code> is another important flag which determines the output type of the model.  This is important to get
right because types may be coerced and this could render weird results.  For instance, if using a model to predict
probabilities and the output type is an integral type, the values returned will likely all be 0.  This is because
coercion from real-valued to integrally valued numbers in done by dropping the decimal places.  If the value is in
the interval [0, 1), then it will be truncated to 0.</li>
  <li><code class="highlighter-rouge">--imports</code> adapts the DSL by importing JVM code.</li>
  <li><code class="highlighter-rouge">-p</code> flag says that base64-encoded protocol buffers will be used as the input format.</li>
</ul>

<p><span class="label">bash script</span></p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>cat <span class="k">$(</span>find <span class="nv">$PWD</span>/aloha-core/src -name <span class="s1">'fizz_buzzs.proto'</span><span class="k">)</span>               <span class="se">\</span>
| aloha-cli/bin/aloha-cli                                              <span class="se">\</span>
  -cp <span class="s2">"</span><span class="nv">$PWD</span><span class="s2">/aloha-io-proto/target/scala-2.11/test-classes"</span>             <span class="se">\</span>
  --modelrunner                                                        <span class="se">\</span>
  --output-type Double                                                 <span class="se">\</span>
  -A                                                                   <span class="se">\</span>
  --imports <span class="s2">"scala.math._,com.eharmony.aloha.feature.BasicFunctions._"</span> <span class="se">\</span>
  -p <span class="s2">"com.eharmony.aloha.test.proto.Testing.UserProto"</span>                 <span class="se">\</span>
  /tmp/aloha-vw-model.json
</code></pre>
</div>

<p><span class="label label-success">output</span></p>

<pre>
0.7329283952713013	CAESBEFsYW4YASUAALhBKg0IARABGQAAAAAAAPA/Kg0IAhACGQAAAAAAAABA
0.7543833255767822	CAESBEthdGUYAioNCAMQAxkAAAAAAAAIQA==
</pre>

<p>If you don’t want the input, just omit the <code class="highlighter-rouge">-A</code> flag or pipe and process the data elsewhere.</p>

<h3 id="sanity-checking-the-aloha-model">Sanity checking the Aloha model</h3>

<p>Notice that the outputs here are:</p>

<ul>
  <li>0.7329283952713013</li>
  <li>0.7543833255767822</li>
</ul>

<p>We saw in the section <a href="#Verifying_the_Model">Verifying the Model</a>, the that predictions were:</p>

<ul>
  <li>0.7329</li>
  <li>0.7544</li>
</ul>

<p>Which lines up.  <em>It appears our model is working!</em></p>

<h2 id="future-plans">Future plans</h2>

<p>The two main areas of future development are</p>

<ol>
  <li>Adding broad classes of IO types suck as Thrift, Scala case classes, etc.</li>
  <li>Adding additional ML libraries underneath the Aloha model facade.</li>
</ol>

<h2 id="ways-to-extend-to-ml-libraries-not-natively-supported">Ways to extend to ML libraries not natively supported</h2>

<p>One can think of this as being analogous to hadoop streaming.  Aloha can be integrated with other platforms
by using it for feature transformation and dataset production.  This is an easy path for the data scientist
as it can alleviate the burden on extracting and transforming features, especially when extract values from
Protocol buffers or Avro.</p>
</section></div></div></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script><script src="/aloha/highlight/highlight.pack.js"></script><script>hljs.configure({
languages:['scala','java','bash']
});
hljs.initHighlighting();
             </script><script src="/aloha/js/main.js"></script><script src="/aloha/js/kazari.js"></script><script>
$(document).ready(function() {
	kazari.KazariPlugin().decorateCode('https://scala-evaluator-212.herokuapp.com/eval', 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.S2F6YXJp.Jl2eqMfw8IakJF93PjxTbrf-8YUJgX5OoOfy5JHE8Yw', '', 'solarized-dark')
})
    </script></body></html>